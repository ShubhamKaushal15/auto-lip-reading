{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924db58c-4754-4eb9-897b-ecd860fdaab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook to generate new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb8546a-44d0-49bc-9b55-43a35fae8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lipnet import ConvGRU\n",
    "\n",
    "import os\n",
    "from functions import *\n",
    "import pandas as pd\n",
    "from data.dataset import LipReadSet\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f41478-d8da-4009-98d5-671ad666f2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec065593-a02f-4205-a340-1eba40a48ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"configs\", f\"lipnet_unseen_mark1.json\"), \"r\") as f:\n",
    "        config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e8c5d75-a560-4182-9295-c562ad159d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias': 'lipnet_unseen_mark1',\n",
       " 'epochs': 15,\n",
       " 'batch_size': 64,\n",
       " 'num_workers': 4,\n",
       " 'learning_rate': 0.0001,\n",
       " 'video_path': '../grid_vidimgs',\n",
       " 'anno_path': '../grid_anno',\n",
       " 'train_list': 'data/unseen/train_dirs.txt',\n",
       " 'validation_list': 'data/unseen/val_dirs.txt',\n",
       " 'test_list': 'data/unseen/test_dirs.txt',\n",
       " 'vid_padding': 75,\n",
       " 'txt_padding': 32}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45f2f1a1-5bed-4515-b3cd-3a6135a4e46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvGRU(\n",
       "  (conv1): Conv3d(3, 32, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))\n",
       "  (pool1): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(32, 64, kernel_size=(3, 5, 5), stride=(1, 1, 1), padding=(1, 2, 2))\n",
       "  (pool2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (pool3): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (gru1): GRU(3072, 256, bidirectional=True)\n",
       "  (gru2): GRU(512, 256, bidirectional=True)\n",
       "  (FC): Linear(in_features=512, out_features=28, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dropout3d): Dropout3d(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = ConvGRU() # Needs to be hard-coded\n",
    "model.to(device)\n",
    "model_save_dir = os.path.join(\"models\")\n",
    "model_save_path = os.path.join(model_save_dir, config['alias'])\n",
    "\n",
    "model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7234502d-50b2-4db4-a198-942eb0b5c5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3d(3, 32, kernel_size=(3, 5, 5), stride=(1, 2, 2), padding=(1, 2, 2))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98694eba-1e64-41dd-80f9-4a77684e6243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loaded_checkpoint = torch.load(os.path.join(model_save_path, f\"{config['alias']}.pt\"))\n",
    "model.load_state_dict(loaded_checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "788ee59c-dd48-4fdd-b841-b51958b0b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_training_example(X, conv_gru_model):\n",
    "    with torch.no_grad():\n",
    "        X = conv_gru_model.conv1(X)\n",
    "        X = conv_gru_model.pool1(X)\n",
    "        X = conv_gru_model.conv2(X)\n",
    "        X = conv_gru_model.pool2(X)\n",
    "        X = conv_gru_model.conv3(X)\n",
    "        x = conv_gru_model.pool3(X)\n",
    "        # (B, C, T, H, W)->(T, B, C, H, W)\n",
    "        x = x.permute(2, 0, 1, 3, 4).contiguous()\n",
    "        # (B, C, T, H, W)->(T, B, C*H*W)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = x.permute(1, 0, 2).contiguous() # (B, T, ...)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fe40801-13ab-49c6-98ac-cf2b65a49417",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LipReadSet(config['video_path'],\n",
    "                config['anno_path'],\n",
    "                config['train_list'],\n",
    "                config['vid_padding'],\n",
    "                config['txt_padding'])\n",
    "\n",
    "validation_dataset = LipReadSet(config['video_path'],\n",
    "                config['anno_path'],\n",
    "                config['validation_list'],\n",
    "                config['vid_padding'],\n",
    "                config['txt_padding'])\n",
    "\n",
    "test_dataset = LipReadSet(config['video_path'],\n",
    "                config['anno_path'],\n",
    "                config['test_list'],\n",
    "                config['vid_padding'],\n",
    "                config['txt_padding'], 'test')\n",
    "     \n",
    "train_loader = DataLoader(train_dataset, \n",
    "                batch_size = config['batch_size'], \n",
    "                num_workers = config['num_workers'],\n",
    "                shuffle = True)\n",
    "\n",
    "validation_loader = DataLoader(validation_dataset, \n",
    "                batch_size = config['batch_size'],\n",
    "                num_workers = config['num_workers'], \n",
    "                shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                batch_size = config['batch_size'],\n",
    "                num_workers = config['num_workers'], \n",
    "                shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "71568e92-8c46-451f-b268-b67dae650abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 360 of 364"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "batch_counter = 0\n",
    "labels = []\n",
    "for X in train_loader:\n",
    "    print(f\"\\rbatch {batch_counter} of 360\", end = '')\n",
    "    #print(X.keys())\n",
    "    #print(X['txt'])\n",
    "    Y = X['txt']\n",
    "    X = X['vid'].to(device)\n",
    "    \n",
    "    #print(X['vid'])\n",
    "    #break\n",
    "    X = encode_training_example(X, model)\n",
    "    \n",
    "    for x,y in zip(X,Y):\n",
    "        x = x.to('cpu')\n",
    "        y = y.to('cpu')\n",
    "        x_np = x.numpy()\n",
    "        x_df = pd.DataFrame(x_np)\n",
    "        y_np = y.numpy()\n",
    "        y_df = pd.DataFrame(y_np)\n",
    "        y_df = y_df.transpose()\n",
    "        y_df.insert(0, \"data\", [f\"train{i}.csv\"], True)\n",
    "        labels.append(y_df)\n",
    "        \n",
    "        x_df.to_csv(f'../encoding_data/train/imgs/train{i}.csv', index=False)\n",
    "        i += 1\n",
    "    \n",
    "    batch_counter += 1    \n",
    "\n",
    "pd.concat(labels).to_csv('../encoding_data/train/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70c9af1f-9101-46ae-868d-ddf102934b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: batch 62 of 63\n",
      "\n",
      "val batch 90 of 91"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "batch_counter = 0\n",
    "labels = []\n",
    "for X in test_loader:\n",
    "    print(f\"\\rtest: batch {batch_counter} of 63\", end = '')\n",
    "    #print(X.keys())\n",
    "    #print(X['txt'])\n",
    "    Y = X['txt']\n",
    "    X = X['vid'].to(device)\n",
    "    \n",
    "    #print(X['vid'])\n",
    "    #break\n",
    "    X = encode_training_example(X, model)\n",
    "    \n",
    "    for x,y in zip(X,Y):\n",
    "        x = x.to('cpu')\n",
    "        y = y.to('cpu')\n",
    "        x_np = x.numpy()\n",
    "        x_df = pd.DataFrame(x_np)\n",
    "        y_np = y.numpy()\n",
    "        y_df = pd.DataFrame(y_np)\n",
    "        y_df = y_df.transpose()\n",
    "        y_df.insert(0, \"data\", [f\"test{i}.csv\"], True)\n",
    "        labels.append(y_df)\n",
    "        \n",
    "        x_df.to_csv(f'../encoding_data/test/imgs/test{i}.csv', index=False)\n",
    "        i += 1\n",
    "    \n",
    "    batch_counter += 1    \n",
    "\n",
    "pd.concat(labels).to_csv('../encoding_data/test/labels.csv', index=False)\n",
    "print(\"\\n\")\n",
    "i = 0\n",
    "batch_counter = 0\n",
    "labels = []\n",
    "for X in validation_loader:\n",
    "    print(f\"\\rval batch {batch_counter} of 91\", end = '')\n",
    "    #print(X.keys())\n",
    "    #print(X['txt'])\n",
    "    Y = X['txt']\n",
    "    X = X['vid'].to(device)\n",
    "    \n",
    "    #print(X['vid'])\n",
    "    #break\n",
    "    X = encode_training_example(X, model)\n",
    "    \n",
    "    for x,y in zip(X,Y):\n",
    "        x = x.to('cpu')\n",
    "        y = y.to('cpu')\n",
    "        x_np = x.numpy()\n",
    "        x_df = pd.DataFrame(x_np)\n",
    "        y_np = y.numpy()\n",
    "        y_df = pd.DataFrame(y_np)\n",
    "        y_df = y_df.transpose()\n",
    "        y_df.insert(0, \"data\", [f\"val{i}.csv\"], True)\n",
    "        labels.append(y_df)\n",
    "        \n",
    "        x_df.to_csv(f'../encoding_data/val/imgs/val{i}.csv', index=False)\n",
    "        i += 1\n",
    "    \n",
    "    batch_counter += 1    \n",
    "\n",
    "pd.concat(labels).to_csv('../encoding_data/val/labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec63c01c-b616-4a11-ae95-6e05dc9580e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -15532.1260\n",
       "1      -30078.5550\n",
       "2      -28204.3710\n",
       "3      -26381.6170\n",
       "4      -23910.1040\n",
       "           ...    \n",
       "3067    -6887.7710\n",
       "3068    -6752.0850\n",
       "3069    -6901.8423\n",
       "3070    -7936.4863\n",
       "3071    -5247.5845\n",
       "Name: 0, Length: 3072, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = pd.read_csv(\"tmp.csv\")\n",
    "image.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ea08bad-e0ba-4a8e-9de1-ed0cd629ce90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      -30078.5550\n",
       "2      -28204.3710\n",
       "3      -26381.6170\n",
       "4      -23910.1040\n",
       "5      -22451.6370\n",
       "           ...    \n",
       "3067    -6887.7710\n",
       "3068    -6752.0850\n",
       "3069    -6901.8423\n",
       "3070    -7936.4863\n",
       "3071    -5247.5845\n",
       "Name: 0, Length: 3071, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.iloc[0,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294dbaee-c4ac-40b1-8245-5e5dd790e0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
